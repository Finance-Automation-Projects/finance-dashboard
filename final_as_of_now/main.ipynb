{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [19 lines of output]\n",
      "      + c:\\Users\\balaj\\anaconda3\\envs\\myenv\\python.exe C:\\Users\\balaj\\AppData\\Local\\Temp\\pip-install-57v74md1\\numpy_6b6c4f9e783c4a5abd7ba7e6b40d62c7\\vendored-meson\\meson\\meson.py setup C:\\Users\\balaj\\AppData\\Local\\Temp\\pip-install-57v74md1\\numpy_6b6c4f9e783c4a5abd7ba7e6b40d62c7 C:\\Users\\balaj\\AppData\\Local\\Temp\\pip-install-57v74md1\\numpy_6b6c4f9e783c4a5abd7ba7e6b40d62c7\\.mesonpy-ulvm16o1 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\balaj\\AppData\\Local\\Temp\\pip-install-57v74md1\\numpy_6b6c4f9e783c4a5abd7ba7e6b40d62c7\\.mesonpy-ulvm16o1\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.2.99\n",
      "      Source dir: C:\\Users\\balaj\\AppData\\Local\\Temp\\pip-install-57v74md1\\numpy_6b6c4f9e783c4a5abd7ba7e6b40d62c7\n",
      "      Build dir: C:\\Users\\balaj\\AppData\\Local\\Temp\\pip-install-57v74md1\\numpy_6b6c4f9e783c4a5abd7ba7e6b40d62c7\\.mesonpy-ulvm16o1\n",
      "      Build type: native build\n",
      "      Project name: NumPy\n",
      "      Project version: 1.26.4\n",
      "      C compiler for the host machine: gcc (gcc 8.3.0 \"gcc (x86_64-posix-seh, Built by strawberryperl.com project) 8.3.0\")\n",
      "      C linker for the host machine: gcc ld.bfd 2.32\n",
      "      C++ compiler for the host machine: c++ (gcc 8.3.0 \"c++ (x86_64-posix-seh, Built by strawberryperl.com project) 8.3.0\")\n",
      "      C++ linker for the host machine: c++ ld.bfd 2.32\n",
      "      Cython compiler for the host machine: cython (cython 3.0.11)\n",
      "      Host machine cpu family: x86_64\n",
      "      Host machine cpu: x86_64\n",
      "      \n",
      "      ..\\meson.build:28:4: ERROR: Problem encountered: NumPy requires GCC >= 8.4\n",
      "      \n",
      "      A full log can be found at C:\\Users\\balaj\\AppData\\Local\\Temp\\pip-install-57v74md1\\numpy_6b6c4f9e783c4a5abd7ba7e6b40d62c7\\.mesonpy-ulvm16o1\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain langchain_community tiktoken langchain-nomic \"nomic[local]\" scikit-learn langgraph tavily-python bs4 firebase-admin langchain-groq langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.50-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting pandas>=1.3.0 (from yfinance)\n",
      "  Using cached pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.16.5 (from yfinance)\n",
      "  Using cached numpy-2.2.0-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting requests>=2.31 (from yfinance)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Using cached multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lxml>=4.9.1 (from yfinance)\n",
      "  Downloading lxml-5.3.0-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\balaj\\anaconda3\\envs\\myenv\\lib\\site-packages (from yfinance) (4.3.6)\n",
      "Collecting pytz>=2022.5 (from yfinance)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.6-py313-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.8.tar.gz (948 kB)\n",
      "     ---------------------------------------- 0.0/948.2 kB ? eta -:--:--\n",
      "     ----------- ---------------------------- 262.1/948.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 948.2/948.2 kB 3.9 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\balaj\\anaconda3\\envs\\myenv\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.17.0)\n",
      "Collecting webencodings (from html5lib>=1.1->yfinance)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\balaj\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.3.0->yfinance)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31->yfinance)\n",
      "  Downloading charset_normalizer-3.4.0-cp313-cp313-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.31->yfinance)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31->yfinance)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.31->yfinance)\n",
      "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading yfinance-0.2.50-py2.py3-none-any.whl (102 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading frozendict-2.4.6-py313-none-any.whl (16 kB)\n",
      "Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-5.3.0-cp313-cp313-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.8/3.8 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.1/3.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 6.4 MB/s eta 0:00:00\n",
      "Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Downloading numpy-2.2.0-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.4/12.6 MB 12.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 5.0/12.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.0/12.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 2.1/11.5 MB 11.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.5/11.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.5 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 11.0 MB/s eta 0:00:00\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml): started\n",
      "  Building wheel for peewee (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for peewee: filename=peewee-3.17.8-py3-none-any.whl size=139012 sha256=27cc8c3cc217e2139083170f32f276fdf5cba2d294a9b1f8b00766c6f23c5ac8\n",
      "  Stored in directory: c:\\users\\balaj\\appdata\\local\\pip\\cache\\wheels\\b2\\69\\9e\\5485afcc187c66def1fab96de510fa77da574ec5343f3a5f89\n",
      "Successfully built peewee\n",
      "Installing collected packages: webencodings, pytz, peewee, multitasking, urllib3, tzdata, soupsieve, numpy, lxml, idna, html5lib, frozendict, charset-normalizer, certifi, requests, pandas, beautifulsoup4, yfinance\n",
      "Successfully installed beautifulsoup4-4.12.3 certifi-2024.12.14 charset-normalizer-3.4.0 frozendict-2.4.6 html5lib-1.1 idna-3.10 lxml-5.3.0 multitasking-0.0.11 numpy-2.2.0 pandas-2.2.3 peewee-3.17.8 pytz-2024.2 requests-2.32.3 soupsieve-2.6 tzdata-2024.2 urllib3-2.2.3 webencodings-0.5.1 yfinance-0.2.50\n"
     ]
    }
   ],
   "source": [
    "! pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtavily\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TavilyClient\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from langchain.schema import HumanMessage\n",
    "from tavily import TavilyClient\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import interface\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "from langchain_groq import ChatGroq\n",
    "import warnings\n",
    "import yfinance as yf\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Or suppress specific warning messages\n",
    "warnings.filterwarnings('ignore', message=\"Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\")\n",
    "### 2. Document Loaders and Vector Stores\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import Document\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEYS\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "GROQ_API_KEY = \"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\"  # Replace with your actual API key\n",
    " \n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "TAVILY_API_KEY = \"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\"  \n",
    "tavily_api_key = \"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\" #change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key = GROQ_API_KEY,\n",
    "    temperature=0,\n",
    "    model_name=\"llama-3.3-70b-versatile\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPORT GENERATOR PROMPT\n",
    "report_generator_prompt = \"\"\"You are a senior equity research analyst tasked with creating a comprehensive investment report.\n",
    "\n",
    "You have been provided with two key analyses:\n",
    "\n",
    "1. Annual Report Analysis:\n",
    "{annual_report_summary}\n",
    "\n",
    "2. Market Sentiment and News Analysis:\n",
    "{sentiment_analysis}\n",
    "\n",
    "3. Company Overview:\n",
    "{company_overview_report}\n",
    "\n",
    "4. Peer Comparison Report:\n",
    "{peer_comparison_report}\n",
    "\n",
    "Based on these inputs, generate a detailed equity research report for {ticker}. Your report should include:\n",
    "\n",
    "1. Executive Summary:\n",
    "- Clear BUY, SELL, or HOLD recommendation with target price range\n",
    "- Key investment highlights\n",
    "- Primary risks\n",
    "\n",
    "2. Financial Analysis (from Annual Report):\n",
    "- Revenue and profit trends\n",
    "- Balance sheet strength\n",
    "- Cash flow analysis\n",
    "- Key ratios and metrics\n",
    "- Management effectiveness\n",
    "\n",
    "3. Market Position & Sentiment:\n",
    "- Recent developments and their impact\n",
    "- Market perception\n",
    "- Competitive position\n",
    "- News flow analysis\n",
    "- Sentiment trends\n",
    "\n",
    "4. Risk Assessment:\n",
    "- Business risks\n",
    "- Financial risks\n",
    "- Market risks\n",
    "- Regulatory risks\n",
    "\n",
    "5. Investment Thesis:\n",
    "- Growth catalysts\n",
    "- Competitive advantages\n",
    "- Valuation perspective\n",
    "- Timeline for expected developments\n",
    "\n",
    "6. Forward Looking Assessment:\n",
    "- Short-term outlook (6-12 months)\n",
    "- Long-term prospects (2-3 years)\n",
    "- Key metrics to monitor\n",
    "\n",
    "Ensure your analysis is data-driven, balanced, and provides clear rationale for all conclusions.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGENT Fucntions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Agent\n",
    "\n",
    "So we are only using the the headlines generated but there is a better concrete score for each aspect in the B which we are not using. Need to incorporate that in this agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsAnalyzer:\n",
    "    def __init__(self, model_name: str = \"llama-3.3-70b-versatile\", groq_api_key:str = GROQ_API_KEY, tavily_api_key: str = tavily_api_key):\n",
    "        \"\"\"Initialize the news analyzer with LLM and Tavily API.\"\"\"\n",
    "        self.llm = ChatGroq(\n",
    "            api_key=groq_api_key,   \n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.3-70b-versatile\"\n",
    "        )\n",
    "        self.tavily_client = TavilyClient(api_key=tavily_api_key or os.getenv(\"TAVILY_API_KEY\"))\n",
    "        self.news_db = interface.NewsDatabase()\n",
    "\n",
    "    def get_headlines(self, ticker: str, limit: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Get and sort headlines for a specific ticker from the database.\"\"\"\n",
    "        try:\n",
    "            # Append '.NS' to the ticker\n",
    "            ticker_with_suffix = ticker + '.NS'\n",
    "            \n",
    "            # Get dataframe from news_db and ensure it's a DataFrame\n",
    "            df_data = self.news_db.to_dataframe()\n",
    "            if isinstance(df_data, tuple):\n",
    "                # If it's a tuple, take the first element assuming it's the DataFrame\n",
    "                df = df_data[0] if df_data else pd.DataFrame()\n",
    "            else:\n",
    "                df = df_data\n",
    "\n",
    "            if df.empty:\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "            # Filter for ticker\n",
    "            ticker_df = df[df['stock_symbol'] == ticker_with_suffix].copy()\n",
    "            \n",
    "            # Convert published_date to datetime\n",
    "            if 'published_date' in ticker_df.columns:\n",
    "                ticker_df['published_date'] = pd.to_datetime(ticker_df['published_date'])\n",
    "            \n",
    "            # Check required columns\n",
    "            if 'title' not in ticker_df.columns or 'url' not in ticker_df.columns:\n",
    "                print(\"Required columns are missing from the DataFrame.\")\n",
    "                print(f\"Available columns: {ticker_df.columns}\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            # Sort by date and get the most recent articles\n",
    "            sorted_df = ticker_df.sort_values('published_date', ascending=False).head(limit)\n",
    "            return sorted_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_headlines: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def get_article_context(self, headline: str, url: str) -> str:\n",
    "        \"\"\"Get additional context about the headline using Tavily API.\"\"\"\n",
    "        try:\n",
    "            search_result = self.tavily_client.search(\n",
    "                query=f\"Context and implications of: {headline}\",\n",
    "                search_depth=\"advanced\",\n",
    "                max_results=2\n",
    "            )\n",
    "            \n",
    "            # Check the type of search_result\n",
    "            if isinstance(search_result, dict):\n",
    "                # If search_result is a dictionary\n",
    "                context = search_result.get('content', 'No additional context found.')\n",
    "            elif isinstance(search_result, list):\n",
    "                # If search_result is a list\n",
    "                contexts = []\n",
    "                for result in search_result:\n",
    "                    if isinstance(result, dict):\n",
    "                        content = result.get('content')\n",
    "                        if content:\n",
    "                            contexts.append(content)\n",
    "                context = \" \".join(contexts) if contexts else \"No additional context found.\"\n",
    "            elif isinstance(search_result, str):\n",
    "                # If search_result is a string\n",
    "                context = search_result\n",
    "            else:\n",
    "                context = \"No additional context found.\"\n",
    "            \n",
    "            return context\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching context: {e}\")\n",
    "            return \"Unable to fetch additional context.\"\n",
    "\n",
    "    def format_date(self, date: pd.Timestamp) -> str:\n",
    "        \"\"\"Convert datetime to a readable format.\"\"\"\n",
    "        return date.strftime('%B %d, %Y')\n",
    "    \n",
    "    def get_financial_metrics(self, row: pd.Series) -> str:\n",
    "        \"\"\"Format non-zero financial metrics into a readable string.\"\"\"\n",
    "        metrics = ['Earnings', 'Revenue', 'Margins', 'Dividend', 'EBITDA', 'Debt']\n",
    "        non_zero_metrics = {metric: row[metric] for metric in metrics if row[metric] != 0}\n",
    "        if not non_zero_metrics:\n",
    "            return \"No financial metrics reported\"\n",
    "        \n",
    "        return '\\n'.join([f\"- {metric}: {value}\" for metric, value in non_zero_metrics.items()])\n",
    "\n",
    "    def format_headlines_for_prompt(self, headlines_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Format headlines and their data into a readable string for the prompt.\"\"\"\n",
    "        formatted_headlines = []\n",
    "        \n",
    "        for idx, row in headlines_df.iterrows():\n",
    "            context = self.get_article_context(row['title'], row['url'])\n",
    "            financial_metrics = self.get_financial_metrics(row)\n",
    "            \n",
    "            headline_text = f\"\"\"Headline {len(formatted_headlines) + 1}:\n",
    "    Date: {self.format_date(row['published_date'])}\n",
    "    Title: {row['title']}\n",
    "    Sentiment Score: {row['Sentiment']}\n",
    "    Financial Metrics:\n",
    "    {financial_metrics}\n",
    "    Context:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "            formatted_headlines.append(headline_text)\n",
    "        \n",
    "        return \"\\n\\n\".join(formatted_headlines)\n",
    "\n",
    "    def generate_analysis(self, headlines_df: pd.DataFrame) -> str:\n",
    "        \"\"\"Generate a comprehensive analysis using the LLM.\"\"\"\n",
    "        if headlines_df.empty:\n",
    "            return \"No recent headlines found for this ticker.\"\n",
    "            \n",
    "        formatted_headlines = self.format_headlines_for_prompt(headlines_df)\n",
    "        sentiment_scores = headlines_df['Sentiment'].tolist()\n",
    "\n",
    "        prompt = f\"\"\"As a stock market analyst, analyze these recent headlines and associated financial metrics for a company. For each headline, evaluate its implications for the company's future performance and market position.\n",
    "\n",
    "Latest Headlines and Data (from most recent to oldest):\n",
    "\n",
    "{formatted_headlines}\n",
    "\n",
    "Please provide a comprehensive analysis that includes:\n",
    "\n",
    "1. Latest Development Analysis:\n",
    "- Analyze the most recent headline in detail\n",
    "- Evaluate any associated financial metrics and their implications\n",
    "- Explain whether this development is BULLISH, BEARISH, or NEUTRAL for the company\n",
    "- Support your assessment with context and available financial data\n",
    "\n",
    "2. Financial Metrics Analysis:\n",
    "- Analyze any changes in key financial metrics (Earnings, Revenue, Margins, etc.)\n",
    "- Identify trends or patterns in the financial data\n",
    "- Explain how these metrics support or contradict the narrative from headlines\n",
    "\n",
    "3. Trend Analysis:\n",
    "- Compare the nature of news across all headlines\n",
    "- Identify if there's an improvement or deterioration in company developments\n",
    "- Note any pattern in the types of news (operational, strategic, market-related)\n",
    "\n",
    "4. Market Sentiment Evolution:\n",
    "- Analyze the sentiment scores: {sentiment_scores}\n",
    "- Explain if the news trajectory suggests strengthening or weakening market position\n",
    "- Note any divergence between sentiment scores and actual news/financial impact\n",
    "\n",
    "5. Forward Looking Assessment:\n",
    "- Based on these developments and metrics, provide a brief outlook\n",
    "- Highlight key areas to monitor going forward\n",
    "- Identify potential risks and opportunities based on the available data\n",
    "\n",
    "Keep the analysis evidence-based and focused on both qualitative news impact and quantitative financial metrics.\"\"\"\n",
    "\n",
    "        response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "        #print(\"SENTIMENT ANALYSIS\",response.content)\n",
    "        return response.content\n",
    "    \n",
    "    def analyze(self, ticker: str) -> Dict[str, Any]:\n",
    "        \"\"\"Main analysis function that processes headlines and returns results.\"\"\"\n",
    "        # Get and process headlines\n",
    "        recent_headlines = self.get_headlines(ticker)\n",
    "        \n",
    "        if recent_headlines.empty:\n",
    "            return {\n",
    "                \"content\": f\"No recent headlines found for {ticker}\",\n",
    "                \"sentiment_scores\": []\n",
    "            }\n",
    "        \n",
    "        # Generate comprehensive analysis\n",
    "        analysis = self.generate_analysis(recent_headlines)\n",
    "        #print(\"SENTIMENT ANALYSIS\",analysis)\n",
    "        return {\n",
    "            \"content\": analysis,\n",
    "            \"sentiment_scores\": recent_headlines['Sentiment'].tolist()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD Firebase access code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initialize_firestore(setup_file):\n",
    "#     try:\n",
    "#         # Check if Firebase apps have already been initialized\n",
    "#         if not firebase_admin._apps:\n",
    "#             cred = credentials.Certificate(setup_file)\n",
    "#             firebase_admin.initialize_app(cred)\n",
    "#         else:\n",
    "#             print(\"Firebase app already initialized.\")\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#     db = firestore.client()\n",
    "#     return db\n",
    "# class FakeEmbeddings(Embeddings):\n",
    "#     def __init__(self, embedding):\n",
    "#         self.embedding = embedding\n",
    "\n",
    "#     def embed_documents(self, texts):\n",
    "#         return [self.embedding[0] for _ in texts]\n",
    "\n",
    "#     def embed_query(self, text):\n",
    "#         return self.embedding[0]\n",
    "# # [AnnualReportAnalyzer class implementation remains the same as before]\n",
    "# def fetch_financials(ticker):\n",
    "#     db = initialize_firestore('secrets_Balaji.json')\n",
    "#     docs = db.collection(\"Stock Financial Data\").limit(1).stream()\n",
    "#     doc = next(docs, None).to_dict()  # Get the first document from the iterator\n",
    "#     return doc[ticker]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma Retrieval code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "def initialize_chromadb(db_path=\"./MasterDatabase\"):\n",
    "    \"\"\"Initialize ChromaDB client\"\"\"\n",
    "    try:\n",
    "        client = chromadb.PersistentClient(db_path)\n",
    "        collection = client.get_collection(\"companies\")  # Adjust collection name if different\n",
    "        return collection\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing ChromaDB: {e}\")\n",
    "        return None\n",
    "\n",
    "def unflatten_dict(d, sep='__'):\n",
    "    \"\"\"\n",
    "    Unflattens a single-level dictionary back into a nested dictionary.\n",
    "    Keys split by `sep` become nested structures.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for key, value in d.items():\n",
    "        parts = key.split(sep)\n",
    "        target = result\n",
    "        for part in parts[:-1]:\n",
    "            target = target.setdefault(part, {})\n",
    "        target[parts[-1]] = value\n",
    "    return result\n",
    "\n",
    "def fetch_financials(ticker):\n",
    "    \"\"\"Fetch financial data for a given ticker from ChromaDB\"\"\"\n",
    "    collection = initialize_chromadb()\n",
    "    if not collection:\n",
    "        raise Exception(\"Failed to initialize ChromaDB\")\n",
    "    \n",
    "    result = collection.get(\n",
    "        ids=[ticker],\n",
    "        include=['metadatas', 'documents']\n",
    "    )\n",
    "    \n",
    "    if not result['ids']:\n",
    "        raise Exception(f\"No data found for ticker: {ticker}\")\n",
    "    \n",
    "    # Unflatten the metadata to match the original Firebase structure\n",
    "    return unflatten_dict(result['metadatas'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Report Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "class AnnualReportAnalyzer:\n",
    "    def __init__(self, ticker, model_name: str = \"llama-3.3-70b-versatile\", groq_api_key: str = GROQ_API_KEY):\n",
    "        self.llm = ChatGroq(\n",
    "            api_key=groq_api_key,   \n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.3-70b-versatile\"\n",
    "        )\n",
    "        self.ticker = ticker\n",
    "        self.setup_retriever_from_chroma(ticker)\n",
    "\n",
    "    def setup_retriever_from_chroma(self, ticker):\n",
    "        \"\"\"\n",
    "        Retrieves stock report data from ChromaDB for a specific ticker\n",
    "        and sets up a retriever.\n",
    "        \n",
    "        Args:\n",
    "            ticker (str): Stock ticker symbol\n",
    "        \"\"\"\n",
    "        # Initialize ChromaDB client\n",
    "        client = chromadb.PersistentClient(\"./database\")\n",
    "        \n",
    "        try:\n",
    "            # Get collection for the ticker\n",
    "            collection = client.get_collection(ticker)\n",
    "            results = collection.get()\n",
    "            \n",
    "            if not results['documents']:\n",
    "                raise ValueError(f\"No stock report found for ticker {ticker}\")\n",
    "            \n",
    "            # Create Document objects\n",
    "            documents = [\n",
    "                Document(\n",
    "                    page_content=doc,\n",
    "                    metadata={'stock': ticker, 'chunk_id': str(idx)}\n",
    "                )\n",
    "                for idx, doc in enumerate(results['documents'])\n",
    "            ]\n",
    "            \n",
    "            # Create Chroma instance with documents\n",
    "            self.vectorstore = Chroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=None,  # ChromaDB handles embeddings internally\n",
    "                persist_directory=f\"./chroma_db_{ticker}\"\n",
    "            )\n",
    "            \n",
    "            # Set up retriever\n",
    "            self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "            \n",
    "            return self.retriever\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {str(e)}\")\n",
    "            # Create a dummy document if no data is found\n",
    "            documents = [Document(\n",
    "                page_content=f\"No text chunks available for {ticker}\",\n",
    "                metadata={'stock': ticker, 'chunk_id': 'dummy'}\n",
    "            )]\n",
    "            \n",
    "            self.vectorstore = Chroma.from_documents(\n",
    "                documents=documents,\n",
    "                embedding=None,\n",
    "                persist_directory=f\"./chroma_db_{ticker}\"\n",
    "            )\n",
    "            self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "            return self.retriever\n",
    "\n",
    "    def analyze_annual_report(self, query: str) -> str:\n",
    "        try:\n",
    "            system_prompt = \"\"\"You are a financial expert and market analyst. Analyze the annual financial report \n",
    "            of the company and provide a precise summary of the company's performance and investment potential.\n",
    "            \n",
    "            Retrieved Context:\n",
    "            {context}\n",
    "            \n",
    "            If the context is limited or missing, focus on providing general analysis based on the available information.\n",
    "            \"\"\"\n",
    "            \n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system_prompt),\n",
    "                (\"human\", \"{input}\"),\n",
    "            ])\n",
    "            \n",
    "            question_answer_chain = create_stuff_documents_chain(\n",
    "                self.llm, \n",
    "                prompt,\n",
    "                document_variable_name=\"context\"\n",
    "            )\n",
    "            \n",
    "            rag_chain = create_retrieval_chain(\n",
    "                self.retriever,\n",
    "                question_answer_chain\n",
    "            )\n",
    "            \n",
    "            results = rag_chain.invoke({\"input\": query})\n",
    "            return results[\"answer\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error in analyze_annual_report: {str(e)}\")\n",
    "            return f\"Unable to analyze annual report for {self.ticker}. Please ensure the required data is available in the database.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Search Agent ( called by peer review agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SectorResearchAgent:\n",
    "    def __init__(self, tavily_api_key = tavily_api_key):\n",
    "        self.tavily_client = TavilyClient(api_key=tavily_api_key)\n",
    "        self.llm = ChatGroq(\n",
    "            api_key=GROQ_API_KEY,\n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.3-70b-versatile\"\n",
    "        )\n",
    "    \n",
    "    def determine_company_sector(self, ticker: str) -> str:\n",
    "        \"\"\"Research and determine company's sector through web search.\"\"\"\n",
    "        try:\n",
    "            # Search for company sector information\n",
    "            results = self.tavily_client.search(\n",
    "                query=f\"What sector and industry does {ticker} company operate in?\",\n",
    "                search_depth=\"advanced\",\n",
    "                max_results=2\n",
    "            )\n",
    "            \n",
    "            # Extract relevant information from search results\n",
    "            sector_info = \"\"\n",
    "            if isinstance(results, list):\n",
    "                sector_info = \" \".join([r.get('content', '') for r in results if 'content' in r])\n",
    "            elif isinstance(results, dict):\n",
    "                sector_info = results.get('content', '')\n",
    "            \n",
    "            # Use LLM to extract sector from the search results\n",
    "            prompt = f\"\"\"Based on this information about {ticker}, what is the company's main sector? \n",
    "            Information: {sector_info}\n",
    "            \n",
    "            Return ONLY the sector name (e.g., 'Technology', 'Healthcare', 'Finance', etc.) without any additional text or explanation.\"\"\"\n",
    "            \n",
    "            response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "            sector = response.content.strip()\n",
    "            \n",
    "            return sector if sector else \"Unknown\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error determining sector for {ticker}: {e}\")\n",
    "            return \"Unknown\"\n",
    "    # Add this method to the SectorResearchAgent class\n",
    "    def research_competitor(self, competitor_ticker: str) -> str:\n",
    "        \"\"\"Research a specific competitor company.\"\"\"\n",
    "        try:\n",
    "            # Search for competitor information using Tavily\n",
    "            queries = [\n",
    "                f\"{competitor_ticker} company performance and market position\",\n",
    "                f\"{competitor_ticker} competitive advantages and strategy\",\n",
    "                f\"{competitor_ticker} recent developments and challenges\"\n",
    "            ]\n",
    "            \n",
    "            findings = []\n",
    "            for query in queries:\n",
    "                results = self.tavily_client.search(\n",
    "                    query=query,\n",
    "                    search_depth=\"advanced\",\n",
    "                    max_results=2\n",
    "                )\n",
    "                \n",
    "                if isinstance(results, list):\n",
    "                    findings.extend(r.get('content', '') for r in results if 'content' in r)\n",
    "                elif isinstance(results, dict):\n",
    "                    findings.append(results.get('content', ''))\n",
    "            \n",
    "            # Use LLM to synthesize findings\n",
    "            if findings:\n",
    "                prompt = f\"\"\"Analyze the following information about {competitor_ticker} and provide a concise summary \n",
    "                of their competitive position, strengths, and challenges:\n",
    "\n",
    "                {' '.join(findings)}\n",
    "\n",
    "                Focus on:\n",
    "                1. Market position\n",
    "                2. Key strengths and weaknesses\n",
    "                3. Recent developments\n",
    "                4. Competitive advantages\n",
    "                \"\"\"\n",
    "                \n",
    "                response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "                return response.content\n",
    "            \n",
    "            return f\"No detailed information found for competitor {competitor_ticker}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error researching competitor {competitor_ticker}: {e}\")\n",
    "            return f\"Unable to analyze competitor {competitor_ticker}\"\n",
    "\n",
    "    def research_sector(self, sector_name: str, ticker: str, timeframe: str = \"recent\") -> str:\n",
    "        \"\"\"Conduct research on sector performance and trends.\"\"\"\n",
    "        if sector_name == \"Unknown\":\n",
    "            # If sector is unknown, perform company-specific industry research\n",
    "            queries = [\n",
    "                f\"{ticker} industry analysis and market trends {timeframe}\",\n",
    "                f\"{ticker} competitive landscape and market position {timeframe}\",\n",
    "                f\"{ticker} industry outlook and market dynamics {timeframe}\"\n",
    "            ]\n",
    "        else:\n",
    "            queries = [\n",
    "                f\"Latest {sector_name} sector performance analysis {timeframe}\",\n",
    "                f\"{sector_name} sector outlook and challenges {timeframe}\",\n",
    "                f\"{sector_name} industry trends and market dynamics {timeframe}\"\n",
    "            ]\n",
    "        \n",
    "        findings = []\n",
    "        for query in queries:\n",
    "            try:\n",
    "                results = self.tavily_client.search(\n",
    "                    query=query,\n",
    "                    search_depth=\"advanced\",\n",
    "                    max_results=3\n",
    "                )\n",
    "                \n",
    "                if isinstance(results, list):\n",
    "                    for result in results:\n",
    "                        if isinstance(result, dict) and 'content' in result:\n",
    "                            findings.append(result['content'])\n",
    "                elif isinstance(results, dict) and 'content' in results:\n",
    "                    findings.append(results['content'])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error in sector research: {e}\")\n",
    "                continue\n",
    "                \n",
    "        return \"\\n\\n\".join(findings) if findings else \"No sector research data available.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedComparison:\n",
    "    def __init__(self, ticker, model_name: str = \"llama-3.3-70b-versatile\", groq_api_key: str = GROQ_API_KEY):\n",
    "        self.llm = ChatGroq(\n",
    "            api_key=groq_api_key,\n",
    "            temperature=0,\n",
    "            model_name=model_name\n",
    "        )\n",
    "        self.ticker = ticker\n",
    "        self.financial_data = fetch_financials(ticker)\n",
    "        self.sector_researcher = SectorResearchAgent()\n",
    "\n",
    "    def enhanced_comparison(self, query: str) -> str:\n",
    "        # Get peer comparison data\n",
    "        peer_data = self.financial_data.get(\"Peer_Comparison\", {})  # Updated to match ChromaDB structure\n",
    "        rivals = [ticker_ for ticker_ in peer_data if ticker_ != self.ticker]\n",
    "        \n",
    "        # Rest of the method remains the same, just ensure the key names match ChromaDB structure\n",
    "        sector = self.sector_researcher.determine_company_sector(self.ticker)\n",
    "        print(f\"Detected sector for {self.ticker}: {sector}\")\n",
    "        \n",
    "        sector_research = self.sector_researcher.research_sector(sector, self.ticker)\n",
    "        competitor_research = {}\n",
    "        for rival in rivals[:2]:\n",
    "            competitor_research[rival] = self.sector_researcher.research_competitor(rival)\n",
    "\n",
    "        system_prompt = (\n",
    "            f\"You are a senior equity research analyst conducting a comprehensive competitive analysis \"\n",
    "            f\"for {self.ticker} in the {sector} sector. \"\n",
    "            f\"Analyze the following data sources to provide a detailed comparison:\\n\\n\"\n",
    "        )\n",
    "\n",
    "        # Add financial metrics\n",
    "        system_prompt += f\"1. FINANCIAL METRICS\\n{self.ticker}:\\n\"\n",
    "        for metric in peer_data[self.ticker]:\n",
    "            system_prompt += f\"- {metric}: {peer_data[self.ticker][metric]}\\n\"\n",
    "        system_prompt += \"\\nCompetitor Financials:\\n\"\n",
    "        for rival in rivals:\n",
    "            system_prompt += f\"{rival}:\\n\"\n",
    "            for metric in peer_data[rival]:\n",
    "                system_prompt += f\"- {metric}: {peer_data[rival][metric]}\\n\"\n",
    "            system_prompt += \"\\n\"\n",
    "\n",
    "        system_prompt += f\"\\n2. SECTOR ANALYSIS\\n{sector_research}\\n\\n\"\n",
    "        system_prompt += \"3. COMPETITOR INSIGHTS\\n\"\n",
    "        for rival, research in competitor_research.items():\n",
    "            system_prompt += f\"\\n{rival} Analysis:\\n{research}\\n\"\n",
    "\n",
    "        analysis_prompt = f\"\"\"\n",
    "        Based on the provided data, create a comprehensive competitive analysis for {self.ticker} in the {sector} sector that includes:\n",
    "        1. Sector Overview:\n",
    "        - Current sector dynamics and trends\n",
    "        - Key challenges and opportunities\n",
    "        - Regulatory environment\n",
    "        2. Competitive Position Analysis:\n",
    "        - Market share and positioning\n",
    "        - Relative financial performance\n",
    "        - Competitive advantages/disadvantages\n",
    "        3. Peer Comparison:\n",
    "        - Detailed financial metrics comparison\n",
    "        - Operational efficiency comparison\n",
    "        - Growth metrics analysis\n",
    "        4. Forward-Looking Assessment:\n",
    "        - Expected sector developments\n",
    "        - Competitive strategy implications\n",
    "        - Growth opportunities and threats\n",
    "        Ensure the analysis is data-driven and provides actionable insights for investment decisions.\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", analysis_prompt)\n",
    "        ])\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"input\": query})\n",
    "        return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company overview Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price_data(ticker: str) -> dict:\n",
    "    \"\"\"Get current stock price and weekly performance\"\"\"\n",
    "    # Add .NS suffix for Indian stocks\n",
    "    ticker_symbol = f\"{ticker}.NS\"\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker_symbol)\n",
    "        # Get current data\n",
    "        current_price = stock.info.get('currentPrice', 0)\n",
    "        \n",
    "        # Get historical data for weekly performance\n",
    "        hist = stock.history(period='5d')\n",
    "        week_open = hist['Open'].iloc[0] if not hist.empty else 0\n",
    "        week_change = ((current_price - week_open) / week_open * 100) if week_open != 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"current_price\": current_price,\n",
    "            \"week_open\": week_open,\n",
    "            \"week_change_percent\": round(week_change, 2)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching stock price data: {e}\")\n",
    "        return {\n",
    "            \"current_price\": 0,\n",
    "            \"week_open\": 0,\n",
    "            \"week_change_percent\": 0\n",
    "        }\n",
    "\n",
    "\n",
    "class Overview:\n",
    "    def __init__(self, ticker, model_name: str = \"llama-3.2-90b-text-preview\", groq_api_key: str = GROQ_API_KEY):\n",
    "        self.llm = ChatGroq(\n",
    "            api_key=groq_api_key,\n",
    "            temperature=0,\n",
    "            model_name=\"llama-3.2-90b-text-preview\"\n",
    "        )\n",
    "        self.ticker = ticker\n",
    "        self.financial_data = fetch_financials(ticker)\n",
    "        self.stock_price_data = get_stock_price_data(ticker)\n",
    "\n",
    "    def company_report(self, query):\n",
    "        # Adjust metrics filtering for ChromaDB structure\n",
    "        metrics = [metric for metric in self.financial_data if metric not in [\"Peer_Comparison\", \"report_url\"]]\n",
    "        \n",
    "        system_prompt = (\n",
    "            f\"You are an expert market analyst and have to provide a detailed overview of the company based on its \"\n",
    "            f\"financials and current market data.\\n\\n\"\n",
    "            f\"Current Market Data for {self.ticker}:\\n\"\n",
    "            f\"- Current Stock Price: ₹{self.stock_price_data['current_price']}\\n\"\n",
    "            f\"- Weekly Opening Price: ₹{self.stock_price_data['week_open']}\\n\"\n",
    "            f\"- Weekly Performance: {self.stock_price_data['week_change_percent']}%\\n\\n\"\n",
    "            f\"Company Financials:\\n\"\n",
    "        )\n",
    "\n",
    "        for metric in metrics:\n",
    "            system_prompt += f\"{metric}:\\n\"\n",
    "            for sub_metric, value in self.financial_data[metric].items():\n",
    "                system_prompt += f\"--- {sub_metric}: {value}\\n\"\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessage(content=system_prompt),\n",
    "            HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "        ])\n",
    "        chain = prompt | self.llm\n",
    "        result = chain.invoke({\"input\": query})\n",
    "        return result.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Dict\n",
    "\n",
    "#  defined graph states\n",
    "def analyze_sentiment(state):\n",
    "    ticker = state[\"ticker\"]\n",
    "    analyzer = NewsAnalyzer()\n",
    "    analysis_result = analyzer.analyze(ticker)\n",
    "    return {\"sentiment_analysis\": analysis_result[\"content\"]}\n",
    "\n",
    "def company_overview_report(state):\n",
    "    ticker = state[\"ticker\"]\n",
    "    overview = Overview(ticker)\n",
    "    company_report = overview.company_report(\n",
    "        f\"Give me a comprehensive overview of {ticker}'s financial performance\"\n",
    "    )\n",
    "    return {\"company_overview_report\": company_report}  # Match state field name\n",
    "\n",
    "def peer_comparison_report(state):\n",
    "    ticker = state[\"ticker\"]\n",
    "    comparison = EnhancedComparison(ticker)\n",
    "    peer_report = comparison.enhanced_comparison(\n",
    "        f\"Provide a competitive analysis of {ticker}\"\n",
    "    )\n",
    "    return {\"peer_comparison_report\": peer_report}\n",
    "\n",
    "def rag_annual_report(state):\n",
    "    ticker = state[\"ticker\"]\n",
    "    analyzer = AnnualReportAnalyzer(ticker)\n",
    "    analysis_result = analyzer.analyze_annual_report(\n",
    "        f\"Analyze {ticker}'s financial performance\"\n",
    "    )\n",
    "    return {\"annual_report_summary\": analysis_result}\n",
    "\n",
    "def generate_equity_report(state):\n",
    "    ticker = state[\"ticker\"]\n",
    "    prompt = report_generator_prompt.format(\n",
    "        ticker=ticker,\n",
    "        sentiment_analysis=state.get(\"sentiment_analysis\", \"\"),\n",
    "        annual_report_summary=state.get(\"annual_report_summary\", \"\"),\n",
    "        company_overview_report=state.get(\"company_overview_report\", \"\"),\n",
    "        peer_comparison_report=state.get(\"peer_comparison_report\", \"\")\n",
    "    )\n",
    "    report = llm.invoke([HumanMessage(content=prompt)])\n",
    "    return {\"equity_research_report\": report.content}\n",
    "\n",
    "# Construct graph\n",
    "class GraphState(TypedDict, total=False):\n",
    "    ticker: str\n",
    "    sentiment_analysis: str\n",
    "    annual_report_summary: str\n",
    "    equity_research_report: str\n",
    "    peer_comparison_report: str\n",
    "    company_overview_report: str \n",
    "# Initialize the workflow\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Set up workflow graph\n",
    "workflow.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
    "workflow.add_node(\"company_overview\", company_overview_report)\n",
    "workflow.add_node(\"peer_comparison\", peer_comparison_report)\n",
    "workflow.add_node(\"rag_annual_report\", rag_annual_report)\n",
    "workflow.add_node(\"generate_equity_report\", generate_equity_report)\n",
    "\n",
    "# Define the flow\n",
    "workflow.set_entry_point(\"analyze_sentiment\")\n",
    "workflow.add_edge(\"analyze_sentiment\", \"company_overview\")\n",
    "workflow.add_edge(\"company_overview\", \"peer_comparison\")\n",
    "workflow.add_edge(\"peer_comparison\", \"rag_annual_report\")\n",
    "workflow.add_edge(\"rag_annual_report\", \"generate_equity_report\")\n",
    "workflow.add_edge(\"generate_equity_report\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()\n",
    "\n",
    "# #Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with a ticker\n",
    "    input_state = {\"ticker\": \"HINDUNILVR\"}\n",
    "    \n",
    "    # Run the analysis\n",
    "    print(\"Starting analysis...\")\n",
    "    result = graph.invoke(input_state)\n",
    "    \n",
    "    print(\"\\nFinal Equity Research Report:\")\n",
    "    print(result.get(\"equity_research_report\", \"Report generation failed.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALL with ticker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with a ticker\n",
    "    input_state = {\"ticker\": \"INFY\"}\n",
    "    \n",
    "    # Run the analysis\n",
    "    print(\"Starting analysis...\")\n",
    "    result = graph.invoke(input_state)\n",
    "    \n",
    "    print(\"\\nFinal Equity Research Report:\")\n",
    "    print(result.get(\"equity_research_report\", \"Report generation failed.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
